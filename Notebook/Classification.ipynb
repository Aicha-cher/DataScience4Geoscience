{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "In this notebook, we will apply several classification algorithms on two data set: *Iris* and *Digits*. The first one is a low dimensional data set while the second one contains more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits, load_iris\n",
    "# Load digits\n",
    "X, y = load_digits(return_X_y=True) # load_iris(return_X_y=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification pipeline\n",
    "Two steps are required\n",
    "- Model selection, i.e. find the optimal hyperparemeters,\n",
    "- Model assessement, i.e. validate the model on unseen data.\n",
    "\n",
    "As said in introduction, scikit-learn offers convenient and generic functions to achieve these steps. In what follow, an example is given for SVM. But it can be extended for any algorithm in scikit-learn, up to a correct definition of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Standardize data\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# Split the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.20, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With kernel methods (and more generaly for any distance based methods), it is a good practice to standardize feature remove dynamics effect. Here we rescale each feature between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definition of the hyperparameters values search\n",
    "degree = sp.arange(1,7) # Degree of the polynomial kernel\n",
    "C = 10.0**sp.arange(0,4)\n",
    "param_grid_svm = dict(degree=degree, C=C, kernel=['poly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html) strategy to select the optimal set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9693593314763231\n",
      "Best set of hyperparameters: {'C': 1000.0, 'degree': 3, 'kernel': 'poly'}\n",
      "0.969401947149\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),  # Set up the classifier\n",
    "                    param_grid=param_grid_svm, \n",
    "                    cv= 5,\n",
    "                    n_jobs=-1) # Do the grid search in parallel\n",
    "grid.fit(X_train, y_train) # Run the grid search\n",
    "print(\"Best score: {}\".format(grid.best_score_))\n",
    "print(\"Best set of hyperparameters: {}\".format(grid.best_params_))\n",
    "print\n",
    "# Learn the optimal model\n",
    "clf = grid.best_estimator_  # Get the best estimator\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict new samples\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute the overall accuracies\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fb958273400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb989a97860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = grid.cv_results_['mean_test_score'].reshape(C.size,degree.size)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "X, Y = sp.meshgrid(degree, C)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "cp = ax.contourf(X, Y, res)\n",
    "ax.scatter(grid.best_params_['degree'],grid.best_params_['C'],color='k')\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Degree\")\n",
    "ax.set_ylabel(\"C\")\n",
    "fig.colorbar(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we would like to compare several kernels. We need can use the same workflow, just by adding one line and modifying one line !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma = 2.0**sp.arange(-4,2) # Scale of the RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid_svm = [dict(kernel=['rbf'],gamma=gamma, C=C),\n",
    "                  dict(kernel=['poly'],degree=degree, C=C)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now now copy/past/run the same code than previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9721448467966574\n",
      "Best set of hyperparameters: {'C': 10.0, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.972183588317\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),  # Set up the classifier\n",
    "                    param_grid=param_grid_svm, \n",
    "                    cv= 5,\n",
    "                    n_jobs=-1) # Do the grid search in parallel\n",
    "grid.fit(X_train, y_train) # Run the grid search\n",
    "print(\"Best score: {}\".format(grid.best_score_))\n",
    "print(\"Best set of hyperparameters: {}\".format(grid.best_params_))\n",
    "print\n",
    "# Learn the optimal model\n",
    "clf = grid.best_estimator_  # Get the best estimator\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict new samples\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute the overall accuracies\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the differents classifiers\n",
    "In the course, we have discussed about three classifiers: QDA, SVM and K-NN. Using the following scripts, we are going to compare their performances on the given data sets. Again, using scikit-learn generic function, it is possible we few lines of code to run all the experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy for LDA: 0.9297635605006954\n",
      "Classification accuracy for SVM: 0.972183588317107 (best parameters {'C': 10.0, 'gamma': 0.125, 'kernel': 'rbf'})\n",
      "Classification accuracy for KNN: 0.9617524339360223 (best parameters {'n_neighbors': 1})\n",
      "Classification accuracy for QDA: 0.9652294853963839 (best parameters {'reg_param': 0.010344827586206898})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Define the classifier list\n",
    "classifiers = [SVC(), KNeighborsClassifier(), QuadraticDiscriminantAnalysis()]\n",
    "names = [\"SVM\", \"KNN\", \"QDA\"]\n",
    "\n",
    "# Define the dictionnary of parameters to optimize\n",
    "param_grids = [dict(kernel=['rbf'], gamma=gamma, C=C),\n",
    "               dict(n_neighbors = sp.arange(1,40)), # number of neighbors for KNN\n",
    "               dict(reg_param = sp.linspace(0,0.1,30)), # Regularization parameter for QDA\n",
    "               ]\n",
    "\n",
    "# Run LDA (no hyperparameters to tune)\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Classification accuracy for {}: {}\".format(\"LDA\",accuracy_score(y_test,y_pred)))\n",
    "    \n",
    "# Run all classifiers\n",
    "for classifier, name, param_grid in zip(classifiers, names, param_grids):\n",
    "    grid = GridSearchCV(classifier, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    clf = grid.best_estimator_ \n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Classification accuracy for {}: {} (best parameters {})\".format(name,accuracy_score(y_test,y_pred),grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "In the previous section, we have selected the best kernel from the polynomial and RBF one. But it is also possible to combine them using [pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) facility offer by scikit-learn. The following code does the job. To make it simple we select the best set of hyperparameters from the previous individual cross-validation. However, it is possible to search for the best combination (if we have a lot of time ...).\n",
    "\n",
    "We first define the CompositeKernel class, which is the weighted summation of the RBF and polynomial kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel, polynomial_kernel\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Convenient Class for summation kernel\n",
    "class CompositeKernel(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,\n",
    "                 mu=0.5,\n",
    "                 gamma=0.125,  \n",
    "                 degree=3):\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.mu = mu\n",
    "        \n",
    "    def transform(self,X):\n",
    "        K = self.mu*rbf_kernel(X,self.X_,gamma=self.gamma)\n",
    "        K += (1-self.mu)*polynomial_kernel(X,self.X_,degree=self.degree)\n",
    "        return K\n",
    "\n",
    "    def fit(self,X,y=None, **fit_params):\n",
    "        self.X_ = X\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "pipe = Pipeline([\n",
    "    ('CK',CompositeKernel()),\n",
    "    ('SVM',SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the range search for the weight paramter *mu* (note that here we do not optimize the parameter of the polynomial and RBF kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9749303621169917\n",
      "Best set of hyperparameters: {'CK__gamma': 0.25, 'CK__degree': 6, 'CK__mu': 0.30000000000000004, 'SVM__kernel': 'precomputed', 'SVM__C': 1.0}\n",
      "0.96314325452\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict([\n",
    "    ('CK__mu', sp.linspace(0,1,num=11)),  # Note the double \"_\" to define parameters of a pipeline\n",
    "    ('CK__gamma', gamma),\n",
    "    ('CK__degree', degree),\n",
    "    ('SVM__C',C),\n",
    "    ('SVM__kernel', ['precomputed']),\n",
    "])\n",
    "grid = GridSearchCV(pipe,  # Set up the classifier -> Here we put our pipeline\n",
    "                    param_grid=param_grid, \n",
    "                    cv= 5,\n",
    "                    n_jobs=-1) # Do the grid search in parallel\n",
    "grid.fit(X_train, y_train) # Run the grid search and wait: 11*6*6*4 tuples of values to be tested !\n",
    "print(\"Best score: {}\".format(grid.best_score_))\n",
    "print(\"Best set of hyperparameters: {}\".format(grid.best_params_))\n",
    "print\n",
    "# Learn the optimal model\n",
    "clf = grid.best_estimator_  # Get the best estimator\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Predict new samples\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute the overall accuracies\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
